# 시간관련 자료 다루기

```{r , include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

 시계열 자료를 분석을 위해 필요한 부분은 날짜에 대한 데이터 변환입니다. 보통의 데이터가 오류를 없애기 위해 날짜를 문자나 숫자로 입력합니다. 이를 날짜 변수로 변환하는 과정을 실습하도록 하겠습니다. 엑셀과 SAS, R은 숫자로 변환된 날짜를 다시 날짜로 변환할 때 기준점이 다릅니다. 그렇게 때문에 주의가 필요합니다. 
 
 필요한 라이브러리를 불러 오겠습니다. 
 

```{r, message = FALSE, warning = FALSE}
rm(list=ls())
Sys.setenv(LANG = "en")
if(!require("tidyverse")) install.packages("tidyverse");library(tidyverse)
if(!require("lubridate")) install.packages("lubridate");library(lubridate)
if(!require("data.table")) install.packages("data.table");library(data.table)
if(!require("htmlTable")) install.packages("htmlTable");library(htmlTable)
if(!require("dlnm")) install.packages("dlnm");library(dlnm)
if(!require("gam")) install.packages("gam");library(gam)

```


 본 자료는 실제 자료를 기반으로 가상의 랜덤 값을 준 것 입니다. 가상의 자료이니 본 분석 결과를 사실로 받아 들이시지는 마시기 바랍니다. 
```{r, message = FALSE, warning = FALSE}
hm0 <- readRDS("data/hm0.rds")
names(hm0)
```



## Date create


 오늘 날짜와 지금 시간, 초를 생성해 보겠습니다. 어떻게 나오나요?
```{r, eval = FALSE}
today()
now()
Sys.time()
```
 주로 날짜는 엑셀 등으로 저잘할 때 문자형식으로 저장합니다. 숫자로 저장하는 경우 변환할때 한번더 수작업을 해야 하기 때문입니다. 또한 월이 있는데, 일이 없거나 하는 경우 변환때 missing 값을로 자동변환됨에도 연구자가 모르고 지나 갈수 있기 때문입니다. 문자로 저장된 날짜를 날짜 변수로 만들어 보겠습니다. 
 <p></p>
`ymd`, `mdy`, `dmy`를 사용하겠습니다.  
```{r}
tibble(ymd("2020-11-10"), 
ymd("20201110"),
ymd("2020-Nov-10"),
mdy("November 10th, 2020"),
dmy("10-Nov-2020")) %>% t() 
```
 모든 날짜는 숫자로 저장되고 있습니다. 2020년 11월 10일은 숫자로는 18576입니다. 기준 날짜인 1970년 1월 1일부터 몇일이 지났는지를 적어 놓은 것입니다. 그래서 아래의 함수를 통해 숫자를 날짜로 변환 할 수 있습니다.  


```{r}
ymd("2020-11-10")%>% as.numeric()
as.Date(18576, origin = "1970-01-01", tz = "UTC")
```
 2020년 11월 10일부터 100일이 지난 날의 날짜는 무엇일까요? 아래와 같이 해볼 수 있습니다. 

```{r}
n100days <- ymd("2020-11-10")%>% as.numeric() +100
as.Date(n100days, origin = "1970-01-01")

```
 


 여기에 hour, minute, second를 추가할 수 있습니다 .
```{r}
tibble(year  = 2020, 
              month = 11, 
              day   = 10, 
              hour  = 11, 
              minute= 15, 
              sec   = 30) %>%
        mutate(now = make_datetime(
                year, month, day, hour, minute, sec
        )) 

```
 
 그럼 그냥 문자로 사용하면 되지 왜 date 형식으로 변환을 하는 걸까요? Date-time components 가 필요하기 때문이기도 합니다. 그리고 연산이 가능해 집니다. 
 
```{r}
datetime <- ymd_hms("2020-11-10 11:30:55")
year(datetime)
month(datetime)
mday(datetime) # 몇 일인지
yday(datetime) # 1월 1일 부터 몇일이 지난는지
wday(datetime) # 월요일 1, 일요일 7
```
 

 몇월인지 무슨 요일인지 생성해 보겠습니다. 
 
```{r}
lubridate::month(datetime, label = TRUE)
lubridate::wday(datetime, label = TRUE)
```
 몇가지 연산을 위해 필요한 days, hours, minutes, seconds, weeks, months, years가 있습니다. 상식적 수순에서 이해할 수 있는데요, 

* 시간간격
    - days: 일수를 나타냅니다. days(100)는 100일의 시간 간격을 나타냅니다. 
    - hours: 시간을 나타냅니다. hours(24)는 24시간의 시간 간격을 나타냅니다.
    - minutes: 분을 나타냅니다. minutes(60)은 60분의 시간 간격을 나타냅니다.
    - seconds: 초를 나타냅니다. seconds(60)은 60초의 시간 간격을 나타냅니다.
    - weeks: 주를 나타냅니다. weeks(2)는 2주의 시간 간격을 나타냅니다.
    - months: 월을 나타냅니다. 주어진 월 수만큼의 평균 일 수를 계산합니다. months(1)은     한 달의 시간 간격을 나타냅니다.
    - years: 연도를 나타냅니다. years(1)은 1년의 시간 간격을 나타냅니다.


우리는 날짜 데이터를 생성하고, 다양한 형식으로 날짜를 변환하는 방법을 배웠습니다. 이번에는 특정 날짜로부터 10일 전의 날짜를 계산하는 방법에 대해 알아보겠습니다. 
R에서 날짜 계산을 용이하게 해주는 lubridate 패키지를 사용하여 이러한 계산을 수행할 수 있습니다. 예를 들어, '2023년 11월 28일'로부터 10일 전의 날짜를 찾고 싶다면, 다음과 같이 할 수 있습니다:


 
## Tutor: heat wave and death

 hm0 자료를 가지고 몇가지 실습을 해보도록 하겠습니다. 

```{r}
head(hm0) %>%
        data.table()
```
 
### date create

날짜를 생성해 보겠습니다. 

```{r}
class(hm0$date)
class(hm0$year)
```
 2002년부터 2015년까지의 자료 입니다. 
```{r}
s1 <- hm0 %>%
  group_by(year) %>%
  count() 
s1
```


 월, 일, 숫자형 월을 생성해 보겠습니다. 
 
```{r}
s2 <- hm0 %>% mutate(months   = lubridate::month(date, label = TRUE, abbr = TRUE)) %>%
  mutate(weekday = lubridate::wday(date, label = TRUE, abbr = TRUE)) %>%
  mutate(month = substr(date, 6, 7)) %>%
  filter(year(date) <= 2015) 
```

 월별 햇볕이 있었던 날의 수를 표로 나타내 보겠습니다. 

```{r}
s2 %>% group_by(months) %>%
  summarize(`number of sunny days` = sum(sun_day, na.rm=TRUE)) %>%
  htmlTable()
```
 
 월별 분포를 그림으로 그려보겠습니다. 
 
```{r baplot months korean}
library(ggplot2)
s2 %>% filter(year ==2015) %>%
        group_by(months) %>%
        ggplot(aes(x= months, y = sun_day, color = months)) +
        geom_point()+
        ggtitle('sunny day counts by months') +
        ylab ('sunny day counts') +
        guides(color = FALSE) 
```

 
 이번에는 최고 기온가 일병 사망 숫자와의  관계를 살폐보겠습니다. 고온과 사망이므로 `filter(month %in% c("06", "07", "08", "09"))`을 이용하겠습니다. `월`을 만들어 놓았으니 `filter`를 이용해서 필요한 월만 가져오면 되겠습니다. tomr 은 total occupation mortality 입니다. `count` 입니다. 35도가 넘으면 사망 숫자가 상승하고 있습니다. 

```{r summer death total, message = FALSE, warning = FALSE, cache=TRUE}
s2 %>% filter(month %in% c("06", "07", "08", "09"), 
              temp_max >15) %>%
  ggplot(aes(x = lag(temp_max), y = tomr)) +
  geom_point(aes(color = months), alpha = 0.5) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
  theme_minimal() +
  xlab('max temperature') + ylab('total death counts') +
  labs(caption ="*row assocation, no lag with linear",
       title=" Association between max temperature \n and daily total death counts "#, subtitle="Beta = -0.014, p = 0.158  before 2009\n  Beta =  0.002,  p = 0.011     from 2009"
  )
```


## home work

### home0

1) 2020-11-10로부터 100일전 날짜는?

2) 2020-11-10로 부터 100일전 날짜의 요일은?

3) 1978-01-21 에 태어난 사람이 2020-12-31까지 몇일을 살았을까?

4) 1919-03-01 은 무슨 요일일까?

```{r, echo = FALSE, eval = FALSE}
diffs <- ymd("2020-12-31")%>% as.numeric() -
         ymd("1978-01-21") %>% as.numeric()    
lubridate::wday(ymd("1919-03-01"), label = TRUE)
```



### home work1
 6, 7, 8, 9월에 고온과 농업인의 사망과의 관련성을 그려보세요. 농업인의 사망은 `occp6` 입니다. 
 
 
```{r summer and death agricultural, echo = FALSE, message = FALSE, warning = FALSE}
s2 %>% filter(month %in% c("06", "07", "08", "09"), 
              temp_max >15) %>%
  ggplot(aes(x = lag(temp_max), y = occp6)) +
  geom_point(aes(color = months), alpha = 0.5) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
  theme_minimal() +
  xlab('max temperature') + ylab('death counts of agricultural worker') +
  labs(caption ="*row assocation, no lag with linear",
       title=" Association between max temperature \n and daily death counts of agricultural workers "#, subtitle="Beta = -0.014, p = 0.158  before 2009\n  Beta =  0.002,  p = 0.011     from 2009"
  )
```


### home work2
12, 1, 2월에 기온과 농업인의 사망과의 관련성을 그려보세요. 기온은 `temp_mean`을 농업인의 사망은 `occp6` 입니다.

```{r winter and death, echo = FALSE, message = FALSE, warning = FALSE}
s2 %>% filter(month %in% c("12", "01", "02")) %>%
  ggplot(aes(x = lag(temp_mean, 2), y = occp6)) +
  geom_point(aes(color = months), alpha = 0.5) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
  theme_minimal() +
  xlab('temperature') + ylab('death counts of agricultural worker') +
  labs(caption ="*row assocation, no lag with linear",
       title=" Association between temperature \n and daily death counts of agricultural workers "#, subtitle="Beta = -0.014, p = 0.158  before 2009\n  Beta =  0.002,  p = 0.011     from 2009"
  )
```




### home work3
  12, 1, 2월에 기온과 관리직의 사망과의 관련성을 그려보세요. 기온은 `temp_mean`을 관리직의 사망은 `occp1` 입니다. 
  
```{r winter and death manager, echo = FALSE, message = FALSE, warning = FALSE}
s2 %>% filter(month %in% c("12", "01", "02")) %>%
  ggplot(aes(x = lag(temp_mean, 2), y = occp1)) +
  geom_point(aes(color = months), alpha = 0.5) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
  theme_minimal() +
  xlab('temperature') + ylab('death counts of manager') +
  labs(caption ="*row assocation, no lag with linear",
       title=" Association between temperature \n and daily death counts of manager "#, subtitle="Beta = -0.014, p = 0.158  before 2009\n  Beta =  0.002,  p = 0.011     from 2009"
  )
```




## Time series data analysis

 기온등의 시계열적 변수가 질병에 어떻게 영향을 미치는지 알고자 할 때 어떻게 해야 할 까요? 우선 전체 직업군의 사망수 'tomr'을 타겟 변수로 지정하겠습니다. 그리고 월별 사망률을 그려보겠습니다.
 
```{r ts1}
s2 <- s2 %>%
  mutate(dz = tomr)

library(plotly)
s2 %>% group_by(months) %>%
  plot_ly( x= ~ months, y = ~dz,
           type = "box", 
           color = ~ months) %>%
  layout(title = 'daily total mortality counts by months', 
         yaxis = list(title ='daily death counts'))

```
 
 월별 사망수의 차이가 관찰되고 있습니다. 이번에는 주별 차이를 관찰해 보겠습니다. 
 
```{r ts2}
s2 %>% group_by(weekday) %>%
  plot_ly( x= ~ weekday, y = ~dz,
           type = "box", 
           color = ~ weekday) %>%
  layout(title = 'daily total mortality counts by weekdays', 
         yaxis = list(title ='daily mortality counts'))

```
 
 고온에 대해서 알아보기 위해 6월부터 9월까지의 데이터로만 해보겠습니다. 몇다 방정식으로 모델을 구성했는지 관찰해 보세요

```{r ts3}
s2 %>% filter(month %in% c("06", "07", "08", "09"), 
              temp_max >15) %>%
  ggplot(aes(x = lag(temp_max, 2), y = dz)) +
  geom_point(aes(color = months), alpha = 0.5) +
  stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1) +
  theme_minimal() +
  xlab('max temperature') + ylab('total death counts') +
  labs(caption ="*row assocation, no lab with linear",
       title=" Association between max temperature \n and daily total death counts ")
```

기본적인 분석을 시행해 보겠습니다. 단순 회귀분석을 시행한다고 생각하고 진행해 보겠습니다. `glm`을 이용해 모델을 만들고, `summary()`를 통해 통계 값을 구해보겠습니다. 
```{r ts4}
s2 <- s2%>% mutate(index = row_number())
mod1 <- glm(data = s2, 
            dz ~ temp_max + weekday + months + ns(index) +       
                 region_id, family = quasipoisson())

summary(mod1)$coefficient[1,]
 
```
 위에서 무엇이 단순 회귀 분서과 시계열 분석의 차이가 될까요? `ns(index)` 부분이 될 것입니다. 좀더 자세히 보겠습니다. 아래는 최고 온도의 변호와 3일의 간격을 두고, 주말 효과는 자유도 6으로 각 주가 각기 다른 효과를 준다고 가정하고, 월은 월을 dummy 변수로 취급하고, index에는 10을 주어서 시계열적 변화를 보정한다 이런 뜻 정도로 이해할 수 있습니다. 여기서 각 3, 6, 10 등의 숫자를 무엇을 넣어야 할지가 시계열 분석에서 고민해야 할 지점 중 하나입니다. 이는 다음 시간에 simulation하는 과정을 통해 알아보고 우선 진행해 보겠습니다. 
 
```{r ts5}
g.mod1 <- glm(data = s2, 
              dz ~ lag(temp_max, 3) + 
                ns(week(date), 6) +
                as.factor(months) +
                ns(index, 10) + region_id, family = quasipoisson())

summary(g.mod1)$coefficient
```

### outside 사망에 대해서

 몇가지를 탐색해보니, 여름철 야외 사망에 대해 연구해 보면 좋겠다는 생각이 드네요. 
 
```{r ts6}
s3 <- s2 %>%
 # filter(region_id %in%c(46)) %>%
  filter(month %in% c( '07', '08', '09')) %>%
  mutate(index = row_number()) 

```
 

 위에서 얼마의 lag time을 주어야 할지 시물레이션을 돌리는 방법을 생각했었습니다. 한 방법은 가능한한 모든 것을 다 해보고 가장 적당하다고 생각되는 것을 해보는 것입니다. 
 
```{r ts7}
library(dlnm)
cb1<- crossbasis(s3$temp_max, lag=14, argvar=list("lin"),  arglag = list(fun="poly", degree=3))

model1<-glm(data=s3,
           outside ~ cb1 + weekday + months + ns(index,10) + as.factor(region_id)#+
              #cloud_mean + sun_day #+ wind_mean + rhum_mean
              , family=quasipoisson())

summary(model1)
pred1.cb1 <-crosspred(cb1, model1, at=1:100, bylag=0.1,  cumul=FALSE)
plot(pred1.cb1, "slices", var=1, col=3, ylab="Relative risk of total death count", #ci.arg=list(density=50, lwd=1),#
     main="Temporal effect of max temperature on total death count", 
     ci.arg=list(density=100, lwd=3),
     cex.main =1.5, 
     xlab="Lag (days)", # family="A",#ylim=c(0.980, 1.02),
     col='black') ;grid()
title(main="* by 1 unit increments of max temperature", 
      family="A", 
      adj=1, line=0, font.main=1, cex=1)
```
 
 `dlnm` distribute lag liner and non-linear model 의 약자로 자세한 것은 http://www.ag-myresearch.com/package-dlnm.html  을 찾아 보시기 바랍니다. 
 여기서 주목할 점은 14일까지의 lag time을 모두 그려서 lag time이 0 인 날 즉 최고 온도가 높은 날 바로 당이에 사망이 높게 올라간다는 것입니다. 이후 4일 후에는 havesting effect가 보이는 군요. 따라서 lag time은 0 설정하고 위험도를 산출하는 방법을 사용하면 좋을 것 같습니다. 또는 그림 그대로를 받아 들여도 좋습니다.
 


## Time series data analysis, regression

## introduction
 시계열적 자료를 분석하고 나타나는 현상과 특정 요인과 관련성을 탐색해보는 시간입니다. 
예를 들어 미세먼지가 높은 날 심혈관 질환이 발생하는가?에 대한 질문에 답하기 위해서 생가할 것이 몇가지 있습니다. 
 미세먼지가 높은 날이란? 심혈관 질환 사망이 높은 날이란? 이 두가지 요소를 검토하게 됩니다. <br>
 그런데 심혈관 질환의 사망은 요일마다 다르고, 계절에 따라 변동하며, 장기 적으로는 점차 증가 또는 감소를 합니다. 그런데 미세먼지도 점차 증가하고 있으니, 단순 상관관계를 보면 미세먼지도 증가 심혈관 사망도 증가하면 양의 관련성을 보이게 됩니다. 
 GDP와 자살의 관계를 보면 어떨까요? 우리나라의 자살률은 증가하고 있습니다. 그런데 GDP도 증가하고 있습니다. 그러니 GDP의 증가와 자살의 증가는 양의 상관관계가 있다고 나옵니다. 맞나요?
 네 심혈관 사망, 자살의 증가의 계절적 요소, 장기간 추세(trend)가 아니라 변동이 미세먼지나 GDP의 변동가 어떠한 관계가 있는지가 우리의 궁금증일 것 입니다. 이러한 궁금증을 R을 이용해서 풀어보도록 하겠습니다. 
 
## 미세먼지와 심혈관사망
 우선 몇가지 시계열 자료 분석의 이해를 돕기 위해 시뮬레이션 자료를 이용해 보겠습니다. 

> x를 일(day) 로 생각하고, 300일 동안 랜덤 변수 y1과 이에 4.5를 곱한 pm(미세먼지)를 가상으로 만들어 보겠습니다. 

```{r, random variable}
set.seed(1)
x  <- 1:300

y1 <- 5*rnorm(300, sd=.1)+15
pm <- y1*4.5
plot(x, pm, type='l')
```

> 여기에 `sin()` 함수를 통해 계절적 요소를 넣고, 0.03을 곱해 long term trend 가 서서히 증가하는 것으로 가정했습니다. 

```{r, seasonal randome}
y2 <- y1*5+ sin(x/2)*5+ x * 0.03 
y2[y2< 0]<-0
y3<-round(y2)
plot(y3, type='l')
```

> 지연 효과와 특정 이벤트가 있는 날을 넣어 보았습니다. 그리고 dataframe을 만들었습니다.

```{r, lag and event date added}
lag <-6
mean(y3)
death <- c(rep(c(80,79,81), (lag/3)), y3[1:(length(y3)-lag)])  
event <- c(rep(1, 30), rep(1, 30), rep(0, 240)) 
eventd <- c(rep(40,30), rep(30, 30), rep(0, 240))
death2<-death+eventd+10
gg <- data.frame(x, pm, y3, death, event, death2) 
head(gg)
```





> 이제 그림을 그려 보겠습니다. 첫 50일에 이벤트가 있어 심혈관 사망이 높고 이후 계절적 요소를 보이며 서서히 증가하고 있습니다. 미세먼지는 random + 계절적 요소로 만들었고요. 

```{r}
plot(x, pm, type="l", col=grey(0.5), ylim=c(50, 140), xlim=c(0, 300))
grid()
lines(x, death2, col=grey(0.7), type="p", cex=0.5)
```


> 이제 단순 회귀 분석을 해보겠습니다. 어떠한 관계가 관찰되시나요. event 때 많이 사망하고, 미세먼지와는 관련이 없네요. 분명 미세먼지와 관련있게 시뮬레이션 해서 만든 자료인데요. 맞습니다. `lag` 과 `seasonality` 보정이 않되었네요.

```{r}
mt3 <- glm(death2 ~ x+sin(x/2)+pm+event)
summary(mt3)$coefficients
```

> 그림으로 확인해 보겠습니다. 무언가 잘못 예측이 되고 있죠? 

```{r, plot regression line simple}
plot(x, pm, type="l", col=grey(0.5), ylim=c(50, 140), xlim=c(0, 300))
grid()
lines(x, death2, col=grey(0.7), type="p", cex=0.5)
mp3 <- c( predict(mt3))
lines(x, mp3, col=75)

```

> 차라리 이렇게 해보는 것은 어떨까요? 시계열적인 요소를 뺀 상태 (residual) 과 미세먼지가 관련이 있나 보는 것입니다 .

```{r, residual plot 1}
mt2 <- glm(death2 ~ x+sin(x/2)+event)
resid_mt2 <-resid(mt2)
risk.m0<-glm(resid_mt2 ~ pm, family=gaussian)
summary(risk.m0)
risk.mp0 <- c( predict(risk.m0))
plot(pm, resid_mt2, type='p', cex=0.5)
lines(pm, (risk.mp0), col=25)

```

 저는 이것이 더 직관적인데요. 심혈관사망에서 시계열적으로 변동이 있는 부분을 뺀 나머지 (residual) 이 pm 이 변동할 때 같이 변동하면 관련성이 있다고 보는 것이지요. 
 
 
> 자 이제 lag 을 줘서 관찰해 보겠습니다. lag을 주면 초반 데이터 숫자가 맞지 않는데요. 이때 pm의 평균 값으로 결측치를 대신해서 해결해 보겠습니다. 

```{r, lag time and plot and regression}
mean(pm)
lag.pm<-6
pm.lag <- c(rep(67.5, lag.pm), pm[1:(length(pm)-lag.pm)])
resid_mt3 <-resid(mt3)
risk.m1<-glm(resid_mt3 ~ pm.lag, family=gaussian)
summary(risk.m1)$coefficients
risk.mp1 <- c( predict(risk.m1))
plot(pm.lag, resid_mt3, type='p', cex=0.5)
lines(pm.lag, risk.mp1, col=25)
```

 네 이제 pm 과 양의 심혈관 사망에 양의 상관관계가 생겼네요. 우리가 원했던 데이터를 그렇게 만들었었습니다.  
> 그림으로 관찰해 보면 빨간색이 lag time을 준것입니다. 누가 더 사망과 관련이 있어 보이나요?

```{r, fit plot 1}
plot(x, resid_mt3, type="l", col=grey(0.5), ylim=c(-15, 40), xlim=c(0, 300))
grid()
lines(x, (pm-50), col=grey(0.7), type="l", cex=0.5)
lines(x, (pm.lag-60), col='red', type="l", cex=0.5)

```


> 지금 까지 고려한 것은 `sin()`으로 계절적 요소, `lag`으로 지연 효과를 고려해서 시계열적 요소를 없앤다음 (residual), pm과 심혈관사망의 관계를 분석하는 방식으로 해보았습니다. 좀더 쉽게 이것을 해보겠습니다. 

```{r, ts summary plot 1}
library(mgcv)
mgam<- gam(death2 ~ s(x, bs="cc", k=100)+event, family=gaussian)
p <- predict(mgam)
plot(x, pm, type="l", col=grey(0.5), ylim=c(40, 150), xlim=c(0, 300), cex=2)
grid()
lines(x, death2, col=grey(0.7), type="p", cex=0.5)
legend(x=250, y=70, 'PM10')
legend(x=150, y=65, 'pm10. lag')
legend(x=210, y=110, 'Obs_death')
legend(x=10, y=50, 'Residual(Obs_Death - Gam(fitting)')
lines(x, p)
lines(x, (resid(mgam)+50), col='blue')
lines(x, pm.lag-10, col='red')

```
> 이것을 회귀 분석으로 구해보겠습니다. k 가 높을 수록 모형은 어떠한 가요? 네 즉 위에 lag time 과 k 값을 어떻게 조정하는 지를 고려해야 합니다. 우선 lag time 어떻게 찾을 까요? 

```{r}
mgam<- gam(death2 ~ s(x, bs="cc", k=100)+event, family=gaussian)
p <- predict(mgam)
risk.pp1 <-glm(death2 ~ p+pm.lag,family=gaussian)
summary(risk.pp1)$coefficients
AIC(risk.pp1)
```

```{r}
mgam150<- gam(death2 ~ s(x, bs="cc", k=10)+event)
p150 <- predict(mgam150)
risk.pp150 <-glm(death2 ~ p150+ pm.lag, family=gaussian)
summary(risk.pp150)$coefficients
AIC(risk.pp1, risk.pp150)
```

> lag 을 찾아 보겠습니다. pm에 대해 lag을 10일까지, 3차 방정식 형태로, 그리고 이를 통해 회귀 분석을 시행해 보세요. 

```{r, dlnm plot 1}
library(dlnm)
cb1.pm <-crossbasis(pm, lag=10, argvar=list(fun="lin"),
     arglag=list(fun="poly", degree=3))
model1 <-glm(death2 ~ cb1.pm+x+event , 
              family=gaussian )
pred1.pm <-crosspred(cb1.pm, model1, at=0:100, bylag=0.1, cumul=TRUE)

plot(pred1.pm, "slices", var=1, col=3, ylab="RR", ci.arg=list(density=15,lwd=2),
     #cumul = TRUE,
main="Association with a 1-unit increase in PM10")

```

> 6일을 lag time으로 하면 좋겠네요. 

이제 6일을 lag time으로 설정해서 회귀 분석을 수행하면 된다는 것을 알았습니다. 이제 남은 것은 시계열적 요소를 어떻게 찾고, 어떻게 보정할지, 그리고 이 과정을 어떻게 합리적으로 할지 더 논의 하면 됩니다. <br>

